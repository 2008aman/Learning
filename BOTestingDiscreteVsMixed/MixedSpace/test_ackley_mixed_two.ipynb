{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5533d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "# use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float64   # use double precision\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.acquisition import LogExpectedImprovement  # safer than EI\n",
    "from botorch.test_functions.synthetic import AckleyMixed\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.constraints import GreaterThan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc352251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AckleyMixed benchmark\n",
    "dim = 10\n",
    "func = AckleyMixed(dim=dim, negate=True)  # negate=True => maximization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c964aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best value: -2.728720250292437\n"
     ]
    }
   ],
   "source": [
    "def generate_mixed_candidates(n, dim):\n",
    "    X = torch.empty(n, dim, dtype=dtype, device=device)\n",
    "    # first dim-3 are binary\n",
    "    X[:, :dim-3] = torch.randint(0, 2, (n, dim-3), dtype=dtype, device=device)\n",
    "    # last 3 are continuous [0,1]\n",
    "    X[:, dim-3:] = torch.rand(n, 3, dtype=dtype, device=device)\n",
    "    return X\n",
    "\n",
    "def generate_initial_data(n=8):\n",
    "    X = generate_mixed_candidates(n, dim)\n",
    "    Y = func(X).unsqueeze(-1)\n",
    "    return X, Y\n",
    "\n",
    "train_X, train_Y = generate_initial_data()\n",
    "print(\"Initial best value:\", train_Y.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71e6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y)\n",
    "model.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a90424",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll = ExactMarginalLogLikelihood(model.likelihood, model).to(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a43cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa716b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 - Loss: 5.230\n",
      "Epoch 20/150 - Loss: 4.985\n",
      "Epoch 30/150 - Loss: 4.763\n",
      "Epoch 40/150 - Loss: 4.573\n",
      "Epoch 50/150 - Loss: 4.420\n",
      "Epoch 60/150 - Loss: 4.299\n",
      "Epoch 70/150 - Loss: 4.207\n",
      "Epoch 80/150 - Loss: 4.138\n",
      "Epoch 90/150 - Loss: 4.088\n",
      "Epoch 100/150 - Loss: 4.052\n",
      "Epoch 110/150 - Loss: 4.027\n",
      "Epoch 120/150 - Loss: 4.010\n",
      "Epoch 130/150 - Loss: 3.999\n",
      "Epoch 140/150 - Loss: 3.993\n",
      "Epoch 150/150 - Loss: 3.988\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 150\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_X)\n",
    "    loss = -mll(output, model.train_targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {loss.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d86e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 | Best value so far: -2.1728\n",
      "Iteration 2 | Best value so far: -2.1728\n",
      "Iteration 3 | Best value so far: -1.7282\n",
      "Iteration 4 | Best value so far: -1.7282\n",
      "Iteration 5 | Best value so far: -1.7282\n"
     ]
    }
   ],
   "source": [
    "N_BATCH = 5\n",
    "\n",
    "for i in range(N_BATCH):\n",
    "    # Re-fit GP on updated data\n",
    "    model = SingleTaskGP(train_X=train_X, train_Y=train_Y)\n",
    "    model.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model).to(train_X)\n",
    "    optimizer = Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_X)\n",
    "        loss = -mll(output, model.train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Acquisition function\n",
    "    acq = LogExpectedImprovement(model=model, best_f=train_Y.max())\n",
    "\n",
    "    # Sample candidate mixed points\n",
    "    candidates = generate_mixed_candidates(n=2000, dim=dim)\n",
    "    acq_values = acq(candidates.unsqueeze(1))\n",
    "    new_x = candidates[acq_values.argmax()]\n",
    "\n",
    "    # Evaluate and add to dataset\n",
    "    new_y = func(new_x.unsqueeze(0)).unsqueeze(-1)\n",
    "    train_X = torch.cat([train_X, new_x.unsqueeze(0)], dim=0)\n",
    "    train_Y = torch.cat([train_Y, new_y], dim=0)\n",
    "\n",
    "    print(f\"Iteration {i+1} | Best value so far: {train_Y.max().item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
